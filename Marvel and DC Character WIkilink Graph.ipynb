{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cbebefc",
   "metadata": {},
   "source": [
    "All Imports Go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d4813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from urllib.parse import quote\n",
    "import re\n",
    "import json\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f70b9b",
   "metadata": {},
   "source": [
    "## Part 1: Download all Marvel & DC Charecter's WikiText\n",
    "### 1. Load Charecter List Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32b8c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel = pickle.load( open( \"data/marvel.pkl\", \"rb\" ) )\n",
    "dc = pickle.load( open( \"data/dc.pkl\", \"rb\" ) )\n",
    "\n",
    "marvel.dropna().head(10)\n",
    "dc.dropna().head(10)\n",
    "\n",
    "marvel = marvel.dropna()\n",
    "dc = dc.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b22ba21",
   "metadata": {},
   "source": [
    "### 2. Create WikiAPI Url From Charecter WikiLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6e6aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_url_for_plaintext(wikiLink):\n",
    "    page_title = re.sub(r\"\\s+\", '_', wikiLink)\n",
    "    \n",
    "    \n",
    "    baseurl = \"https://en.wikipedia.org/w/api.php?\"\n",
    "    action = \"action=query\"\n",
    "    title = \"titles=\" + quote(page_title)\n",
    "\n",
    "    content = \"prop=extracts&exintro=1&explaintext=1&redirects=1\"\n",
    "    dataformat =\"format=json\"\n",
    "\n",
    "    # https://en.wikipedia.org/w/api.php?action=query&prop=extracts&titles=Abomination_%28character%29&format=json&exintro=1&explaintext=1\n",
    "    return \"{}{}&{}&{}&{}\".format(baseurl, action, content, title, dataformat)\n",
    "\n",
    "# Get API For WikiText\n",
    "def get_api_url(wikiLink):\n",
    "    page_title = re.sub(r\"\\s+\", '_', wikiLink)\n",
    "       \n",
    "    baseurl = \"https://en.wikipedia.org/w/api.php?\"\n",
    "    action = \"action=query\"\n",
    "    title = \"titles=\" + quote(page_title)\n",
    "\n",
    "    content = \"prop=revisions&rvprop=content&redirects=1&rvslots=main\"\n",
    "    dataformat =\"format=json\"\n",
    "\n",
    "    # https://en.wikipedia.org/w/api.php?action=query&titles=Abomination_(character)&prop=revisions&rvprop=content&rvslots=main&format=json\n",
    "    return \"{}{}&{}&{}&{}\".format(baseurl, action, content, title, dataformat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c194f9e",
   "metadata": {},
   "source": [
    "### 3. Get WikiText From Wikilink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "721fb223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Plaintext of short Description\n",
    "def get_wiki_plaintext(wikiLink):\n",
    "    query = get_api_url_for_plaintext(wikiLink)   \n",
    "\n",
    "    response = urllib.request.urlopen(query)\n",
    "    \n",
    "    if response.getcode() != 200:\n",
    "        return np.nan\n",
    "    \n",
    "    data = response.read()\n",
    "    encoding = response.info().get_content_charset('utf-8')\n",
    "    jsonData = json.loads(data.decode(encoding))\n",
    "\n",
    "    page = next(iter(jsonData['query']['pages'].values()))\n",
    "    return page['extract'] if \"extract\" in page else np.nan\n",
    "\n",
    "# marvel[\"WikiLink\"].head(5).apply(get_wiki_plaintext)\n",
    "\n",
    "\n",
    "# Get wikitext of fullpage which contains link\n",
    "def get_wiki_text(wikiLink):\n",
    "    query = get_api_url(wikiLink)   \n",
    "\n",
    "    response = urllib.request.urlopen(query)\n",
    "    \n",
    "    if response.getcode() != 200:\n",
    "        return np.nan\n",
    "    \n",
    "    data = response.read()\n",
    "    encoding = response.info().get_content_charset('utf-8')\n",
    "    jsonData = json.loads(data.decode(encoding))\n",
    "\n",
    "    page = next(iter(jsonData['query']['pages'].values()))\n",
    "    \n",
    "    try: \n",
    "        return page[\"revisions\"][0][\"slots\"][\"main\"][\"*\"] \n",
    "    except KeyError as error: \n",
    "        return np.nan\n",
    "\n",
    "\n",
    "\n",
    "# dc[\"WikiLink\"].iloc[100:].apply(get_wiki_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a4696",
   "metadata": {},
   "source": [
    "### 4. Save Text To File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "726a46c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(directory_ext):\n",
    "    path = os.path.join(os.getcwd(), directory_ext)\n",
    "\n",
    "    try: \n",
    "        os.mkdir(path)\n",
    "    except OSError as error: \n",
    "        return None\n",
    "\n",
    "create_directory(\"data\")\n",
    "create_directory(\"data/Marvel\")\n",
    "create_directory(\"data/DC\")\n",
    "\n",
    "def get_file_name_from_wikilink(wikilink):\n",
    "    return re.sub(r\"[^\\w\\s]\", '', wikilink) + \".txt\"\n",
    "\n",
    "def save_file(text, wikilink, directory_ext):\n",
    "    name = get_file_name_from_wikilink(wikilink)\n",
    "    \n",
    "    file = open(directory_ext + os.sep + name, \"w\", encoding=\"utf-8\") \n",
    "    file.write(text) \n",
    "    file.close()\n",
    "    \n",
    "\n",
    "def save_wikitext(wikiLink, directory_ext):\n",
    "    text = get_wiki_text(wikiLink)\n",
    "    \n",
    "    if  isinstance(text,str) and text != \"\":\n",
    "        save_file(text, wikiLink, directory_ext)\n",
    "        return text\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "# save_wikitext(dc[\"WikiLink\"][0],\"data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f59d3c3",
   "metadata": {},
   "source": [
    "### 5. Save a Marvel and DC charecter's wikipages to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aaacbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_marvel_pages(wikiLink): \n",
    "    return save_wikitext(wikiLink, \"data/Marvel\")\n",
    "def download_dc_pages(wikiLink): \n",
    "    return save_wikitext(wikiLink, \"data/DC\")\n",
    "    \n",
    "# download_marvel_pages(\"Achebe (comics)\")\n",
    "# download_dc_pages(\"Abin Sur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e428fbac",
   "metadata": {},
   "source": [
    "### 6. Download wikitext , generate Datafram and save as picle file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64bffa",
   "metadata": {},
   "source": [
    "```py\n",
    "marvel[\"wikitext\"] = marvel[\"WikiLink\"].apply(download_marvel_pages)\n",
    "dc[\"wikitext\"] = dc[\"WikiLink\"].apply(download_dc_pages)\n",
    "\n",
    "marvel.dropna().to_pickle(\"./data/Marvel_Characters_Wikitext.pkl\")\n",
    "dc.dropna().to_pickle(\"./data/DC_Characters_Wikitext.pkl\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91acfe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel[\"wikitext\"] = marvel[\"WikiLink\"].apply(download_marvel_pages)\n",
    "dc[\"wikitext\"] = dc[\"WikiLink\"].apply(download_dc_pages)\n",
    "\n",
    "marvel.dropna().to_pickle(\"./data/Marvel_Characters_Wikitext.pkl\")\n",
    "dc.dropna().to_pickle(\"./data/DC_Characters_Wikitext.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27358862",
   "metadata": {},
   "source": [
    "## Part 2: Create Graph of Marvel and DC universe using downloaded wikitext\n",
    "\n",
    "We will create a DiGraph where every node is the marvel & DC charecter and edge will be every link in their wikitext to other charecter.\n",
    "\n",
    "### 1. Load The Downloaded data:\n",
    " We can use the downloaded text file for this purpose using the below code:\n",
    " \n",
    "```py\n",
    "def get_directory_list(directory_ext):\n",
    "    # Get the path of current working directory\n",
    "    path = os.getcwd() + os.sep + directory_ext\n",
    "    return os.listdir(path)  # Get the list of all files and directories in current working directory\n",
    "\n",
    "\n",
    "def read_all_files(directory_ext):\n",
    "    file_name_list = get_directory_list(directory_ext)\n",
    "    text_dict = {}\n",
    "\n",
    "    for file_name in file_name_list:\n",
    "        file_name = directory_ext + os.sep + file_name\n",
    "\n",
    "        try:\n",
    "            text = \"\"\n",
    "            file = open(file_name, 'r')\n",
    "            Lines = file.readlines()\n",
    "            for line in Lines:\n",
    "                text = text + line.strip()\n",
    "            file.close()\n",
    "            text_dict[file_name_list] = text\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return text_dict\n",
    "\n",
    "marvel_list = read_all_files(\"data/Marvel\")\n",
    "dc_list = read_all_files(\"data/DC\")\n",
    "```\n",
    "  But this will be slow. I prefer to use the curresponding pickle file which we have saved in previous step.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e03ae177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CharacterName</th>\n",
       "      <th>WikiLink</th>\n",
       "      <th>wikitext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Abomination</td>\n",
       "      <td>Abomination (character)</td>\n",
       "      <td>{{For|the biblical term|Abomination (Bible)}}\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Absorbing Man</td>\n",
       "      <td>Absorbing Man</td>\n",
       "      <td>{{Short description|Marvel Comics fictional ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Achebe</td>\n",
       "      <td>Achebe (comics)</td>\n",
       "      <td>{{Short description|Fictional supervillain app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Agent</td>\n",
       "      <td>Agent (comics)</td>\n",
       "      <td>{{Short description|Fictional character in Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Agent X</td>\n",
       "      <td>Agent X (Marvel Comics)</td>\n",
       "      <td>{{short description|Fictional comic book chara...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  CharacterName                 WikiLink  \\\n",
       "0            0    Abomination  Abomination (character)   \n",
       "1            1  Absorbing Man            Absorbing Man   \n",
       "5            5         Achebe          Achebe (comics)   \n",
       "13          13          Agent           Agent (comics)   \n",
       "14          14        Agent X  Agent X (Marvel Comics)   \n",
       "\n",
       "                                             wikitext  \n",
       "0   {{For|the biblical term|Abomination (Bible)}}\\...  \n",
       "1   {{Short description|Marvel Comics fictional ch...  \n",
       "5   {{Short description|Fictional supervillain app...  \n",
       "13  {{Short description|Fictional character in Mar...  \n",
       "14  {{short description|Fictional comic book chara...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read all downloaded text data\n",
    "Marvel_Characters_Wikitext = pd.read_pickle(\"./data/Marvel_Characters_Wikitext.pkl\")\n",
    "DC_Characters_Wikitext = pd.read_pickle(\"./data/DC_Characters_Wikitext.pkl\")\n",
    "Marvel_Characters_Wikitext.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343b0bc",
   "metadata": {},
   "source": [
    "### 2. Create A DiGraph Containing All Character as Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b2e8e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph(name=\"Marvel & DC charecter wikilink Graph\")\n",
    "\n",
    "def add_node(character_name,universe_name):\n",
    "    G.add_node(character_name, universe=universe_name)\n",
    "def add_marvel_charecter(character_name):\n",
    "    add_node(character_name,\"Marvel\")\n",
    "def add_dc_charecter(character_name):\n",
    "    add_node(character_name,\"DC\")\n",
    "\n",
    "Marvel_Characters_Wikitext[\"CharacterName\"].apply(add_marvel_charecter)\n",
    "DC_Characters_Wikitext[\"CharacterName\"].apply(add_dc_charecter)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901aefcf",
   "metadata": {},
   "source": [
    "### 2. Find All The outgoing link of a particuler charecter wikitext page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb4b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_links(text):\n",
    "    link_list =  re.findall(r\"\\[\\[(.*?)\\]\\]\", text)\n",
    "    links = set()\n",
    "    \n",
    "    for link in link_list:\n",
    "        links.update(link.split(\"|\"))\n",
    "    return list(links)\n",
    "\n",
    "# get_links(Marvel_Characters_Wikitext[\"wikitext\"][0])\n",
    "\n",
    "marvel_link_charecter_dict = {}\n",
    "dc_link_charecter_dict = {}\n",
    "\n",
    "for link, name in zip(Marvel_Characters_Wikitext[\"WikiLink\"], Marvel_Characters_Wikitext[\"CharacterName\"]):\n",
    "    marvel_link_charecter_dict[link] =  name\n",
    "for link, name in zip(DC_Characters_Wikitext['WikiLink'], DC_Characters_Wikitext['CharacterName']):\n",
    "    dc_link_charecter_dict[link] =  name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16a15b6",
   "metadata": {},
   "source": [
    "### 3. Add all the edges to our graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d53df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_link_to_graph(name,link):\n",
    "    if link in marvel_link_charecter_dict:\n",
    "        G.add_edge(name, marvel_link_charecter_dict[link])\n",
    "    elif link in dc_link_charecter_dict:\n",
    "        G.add_edge(name, dc_link_charecter_dict[link])\n",
    "\n",
    "for name,text in zip(Marvel_Characters_Wikitext[\"CharacterName\"], Marvel_Characters_Wikitext[\"wikitext\"]):\n",
    "    for link in get_links(text):\n",
    "        add_link_to_graph(name,link)\n",
    "\n",
    "for name,text in zip(DC_Characters_Wikitext[\"CharacterName\"], DC_Characters_Wikitext[\"wikitext\"]):\n",
    "    for link in get_links(text):\n",
    "        add_link_to_graph(name,link)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d78cec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37b3f393",
   "metadata": {},
   "source": [
    "### 4. Remove all the nodes which don't have any edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc8a9059",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in list(G.nodes()):\n",
    "    if G.in_degree(node) == 0 and G.out_degree(node) == 0:\n",
    "        G.remove_node(node)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0ec3b",
   "metadata": {},
   "source": [
    "## Part 2: Save The graph as edgelist.\n",
    "Below Code will save the graph `comic_characters_universe.edgelist` in our data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89cb8140",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_edgelist(G, \"data/comic_characters_universe.edgelist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa540f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
